{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4ea5c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from simulation.unity_simulator.comm_unity import UnityCommunication\n",
    "import torch\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5036689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simulation.evolving_graph.execut import ScriptExecutor\n",
    "from simulation.evolving_graph import check_programs\n",
    "import dataset_utils.add_preconds as add_preconds\n",
    "from simulation.evolving_graph import utils\n",
    "from simulation.evolving_graph.scripts import (\n",
    "    Action,\n",
    "    ScriptParseException, Script, ScriptLine, ScriptObject,\n",
    "    read_script_from_string, read_script_from_list_string,\n",
    ")\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f20c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils.execute_script_utils import (\n",
    "    parse_exec_script_file, render_script,\n",
    "    obtain_scene_id_from_path, render_script_from_path,\n",
    ")\n",
    "from unity_simulator.comm_unity import UnityCommunication\n",
    "comm = UnityCommunication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb8ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47425440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.reset(env_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ff30137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm.add_character()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abbf50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, graph_input = comm.environment_graph()\n",
    "graph_input = check_programs.translate_graph_dict_nofile(graph_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "243134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_script_file(filename):\n",
    "    with open(filename) as f:\n",
    "        title = f.readline().strip()\n",
    "        assert '[' not in title\n",
    "        description = f.readline().strip()\n",
    "        assert '[' not in description\n",
    "        script_lines = []\n",
    "        script_lines_str = []\n",
    "        index = 1\n",
    "        for line in f:\n",
    "            if '[' not in line:\n",
    "                continue\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and not line.startswith('#'):\n",
    "                params = []\n",
    "\n",
    "                patt_action = r'^\\[(\\w+)\\]'\n",
    "                patt_params = r'\\<(.+?)\\>\\s*\\((.+?)\\.(.+?)\\)'\n",
    "\n",
    "                action_match = re.search(patt_action, line.strip())\n",
    "                if not action_match:\n",
    "                    raise ScriptParseException('Cannot parse action')\n",
    "                action_string = action_match.group(1).upper()\n",
    "                if action_string not in Action.__members__:\n",
    "                    raise ScriptParseException('Unknown action \"{}\"', action_string)\n",
    "                action = Action[action_string]\n",
    "\n",
    "                param_match = re.search(patt_params, action_match.string[action_match.end(1):])\n",
    "                while param_match:\n",
    "                    params.append(ScriptObject(param_match.group(1), int(param_match.group(2))))\n",
    "                    param_match = re.search(patt_params, param_match.string[param_match.end(2):])\n",
    "\n",
    "                if len(params) != action.value[1]:\n",
    "                    raise ScriptParseException('Wrong number of parameters for \"{}\". Got {}, expected {}',\n",
    "                                               action.name, len(params), action.value[1])\n",
    "                script_lines.append(ScriptLine(action, params, index))\n",
    "                script_lines_str.append('[{}]'.format(action.name) + ''.join([' ' + str(par) for par in params]))\n",
    "                index += 1\n",
    "    return title, description, Script(script_lines), script_lines_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab47f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title, description, script, script_str = read_script_file(\n",
    "    \"dataset/programs_processed_precond_nograb_morepreconds/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file1003_2.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e09e7c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go to the home office and write an email'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a151d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preconds = add_preconds.get_preconds_script(script_str).printCondsJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c729bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = check_programs.check_script(script, preconds, graph_path=None, inp_graph_dict=graph_input)\n",
    "helper = utils.graph_dict_helper(max_nodes=check_programs.max_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03dfbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "message, executable, final_state, graph_state_list, id_mapping, info, modif_script = check_programs.check_one_program(\n",
    "        helper, script, preconds, graph_input, w_graph_list=True, modify_graph=True,\n",
    "        id_mapping={}, place_other_objects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f062d3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08673fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8dc125",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5TokenizerFast.from_pretrained(\"t5-large\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ed2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ca2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20eccdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_envs = list(range(1,6))\n",
    "heldout_envs = [6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "014a81ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13bd09d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval 1: seen environments\n",
    "seen_env_fns = []\n",
    "# Eval 2: held-out environments\n",
    "held_out_env_fns = []\n",
    "# Baseline 1: goal -> actions\n",
    "# Baseline 1.5: goal -> actions (NL-ified)\n",
    "# Baseline 2: goal, obs -> actions\n",
    "# Baseline 2.5: goal, obs -> actions (NL-ified)\n",
    "# Baseline 3: goal -> description -> actions\n",
    "# Baseline 3.5: goal -> description -> actions (NL-ified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2e180b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_dir in glob.glob(\"dataset/programs_processed_precond_nograb_morepreconds/executable_programs/*\"):\n",
    "    for file in glob.glob(os.path.join(scene_dir, \"results_intentions_march-13-18\", \"*\")):\n",
    "        all_data_fns.append(file)\n",
    "        scene_id = int(os.path.split(scene_dir)[-1].split('_')[0].split('TrimmedTestScene')[-1])\n",
    "        if scene_id in seen_envs:\n",
    "            seen_env_fns.append(file)\n",
    "        else:\n",
    "            held_out_env_fns.append(file)\n",
    "#     title, description, script, script_str = read_script_file(\n",
    "#         f\"dataset/programs_processed_precond_nograb_morepreconds/executable_programs/TrimmedTestScene1_graph/results_intentions_march-13-18/file1003_2.txt\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1fc794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2573"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seen_env_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "edaf3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(seen_env_fns)\n",
    "train_fns = seen_env_fns[:int(.8*len(seen_env_fns))]\n",
    "eval_data_seen_env = seen_env_fns[int(.8*len(seen_env_fns)):]\n",
    "eval_data_new_env = held_out_env_fns\n",
    "random.shuffle(eval_data_new_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "db242f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2058 515 1520\n"
     ]
    }
   ],
   "source": [
    "print(len(train_fns), len(eval_data_seen_env), len(eval_data_new_env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ece02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptDataEntry:\n",
    "    state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "13531565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptStepDataEntry:\n",
    "    def __init__(\n",
    "        self,\n",
    "        goal: str,\n",
    "        description: str,\n",
    "        action: ScriptLine,\n",
    "        action_str: str,\n",
    "        action_history: list,  # list of Action (before `action`)\n",
    "        action_str_history: list,  # list of str (before `action_str`)\n",
    "        curr_state: dict,  # before executing the instruction\n",
    "        state_history: list,  # list of state dicts (before `curr_state`)\n",
    "        #observation: dict,\n",
    "        env_id: int,\n",
    "        transcript_id: str,\n",
    "        filename: str,\n",
    "        step_idx: int,\n",
    "    ):\n",
    "        self.goal = goal\n",
    "        self.description = description\n",
    "        self.action = action\n",
    "        self.action_str = action_str\n",
    "        self.action_history = action_history\n",
    "        self.action_str_history = action_str_history\n",
    "        self.curr_state = curr_state\n",
    "        #self.observation = observation\n",
    "        self.state_history = state_history\n",
    "        self.env_id = env_id\n",
    "        self.transcript_id = transcript_id\n",
    "        self.filename = filename\n",
    "        self.step_idx = step_idx\n",
    "    \n",
    "    def __str__(self):\n",
    "        return json.dumps({\n",
    "            'goal': self.goal, 'desc': self.description, 'action': self.action_str,\n",
    "            'action_history': self.action_history, 'action_str_history': self.action_str_history,\n",
    "            'curr_state': self.curr_state, 'state_history': state_history,\n",
    "            'step_idx': self.step_idx,\n",
    "        }, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c229401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(state_list_filename):\n",
    "    with open(state_list_filename) as f:\n",
    "        state_list = json.load(f)\n",
    "        return state_list['graph_state_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5310ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4679d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptDataset(Dataset):\n",
    "    \"\"\"\n",
    "    load data\n",
    "    \"\"\"\n",
    "    def __init__(self, filenames: list, split: str):\n",
    "        # TODO where did Shuang get observations? (have to run data?)\n",
    "        self.split = split\n",
    "        self.data = []\n",
    "        for fn in tqdm.tqdm(filenames):\n",
    "            title, description, script, script_str = read_script_file(fn)\n",
    "            state_fn = fn.replace('executable_programs', 'state_list').replace('.txt', '.json')\n",
    "            state_list = load_state_dict(state_fn)\n",
    "            env_id = int(fn.split('/')[-3].split('_')[0].split('TrimmedTestScene')[-1]) - 1\n",
    "            transcript_id = os.path.split(fn)[-1].split('.')[0]\n",
    "            assert len(state_list) == len(script_str) + 1\n",
    "            for step in range(len(script_str)):\n",
    "                entry = TranscriptStepDataEntry(\n",
    "                    goal=title, description=description,\n",
    "                    action=script[step], action_str=script_str[step],\n",
    "                    action_history=script[:step], action_str_history=script_str[:step],\n",
    "                    curr_state=state_list[step], state_history=state_list[:step],\n",
    "                    env_id=env_id, transcript_id=transcript_id,\n",
    "                    filename='/'.join(fn.split('/')[-3:]), step_idx=step,\n",
    "                )\n",
    "                self.data.append(entry)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "#     data_entry = {\n",
    "#         'states': states,\n",
    "#         'fn': fn,\n",
    "#         'env_id': env_id,\n",
    "#         'transcript_id': transcript_id,\n",
    "#     }\n",
    "#     data.append(data_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b4296d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██████████████████                                                                        | 2/10 [00:00<00:00, 13.94it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████████                                             | 5/10 [00:00<00:00, 14.77it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████████████                  | 8/10 [00:00<00:00, 17.21it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.53it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "train_data = TranscriptDataset(train_fns[:10], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c0bd316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[FIND] <spectacles> (1)', '[GRAB] <spectacles> (1)']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[2].action_str_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef65842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to a separate utilities file\n",
    "def convert_action_to_nl(action: ScriptLine):\n",
    "    # [FIND] <item> (1)  ->  find item 1.\n",
    "    # [PUTIN] <obj> (1) <subj> (2)  ->  put obj in subj\n",
    "    \n",
    "    return action_str_nl\n",
    "\n",
    "    \n",
    "def convert_nl_to_action(action_nl: str):\n",
    "    return action_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "747a9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptDataLoader(DataLoader):\n",
    "    def __init__(\n",
    "        self, dataset: TranscriptDataset,\n",
    "        batch_size, tokenizer, device='cpu',\n",
    "        get_nlified_actions=False,\n",
    "    ):\n",
    "        super().__init__(dataset, batch_size, collate_fn=self.collate_fn)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.get_nlified_actions = get_nlified_actions\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        batch_goal = self.tokenizer(\n",
    "            [ex.goal for ex in batch], return_tensors='pt', padding=True, truncation=True,\n",
    "        )\n",
    "        batch_description = self.tokenizer(\n",
    "            [ex.description for ex in batch], return_tensors='pt', padding=True, truncation=True,\n",
    "        )\n",
    "        batch_action = self.tokenizer(\n",
    "            [ex.action_str for ex in batch], return_tensors='pt', padding=True, truncation=True,\n",
    "        ).to(self.device)\n",
    "        batch_action_history = self.tokenizer(\n",
    "            ['. '.join(ex.action_str_history) for ex in batch], return_tensors='pt', padding=True, truncation=True,\n",
    "        ).to(self.device)\n",
    "        # TODO how to encode states??\n",
    "        batch_states = [ex.curr_state for ex in batch]\n",
    "#         self.tokenizer(\n",
    "#             [ex.curr_state for ex in batch], return_tensors='pt', padding=True, truncation=True,\n",
    "#         )\n",
    "        return_batch = {\n",
    "            'goals': batch_goal,\n",
    "            'descriptions': batch_description,\n",
    "            'actions': batch_action,\n",
    "            'prev_actions': batch_action_history,\n",
    "            'states': batch_states,\n",
    "        }\n",
    "        \n",
    "        if self.get_nlified_actions:\n",
    "            import pdb; pdb.set_trace()\n",
    "            return_batch['actions_nl'] = self.tokenizer(\n",
    "                [convert_action_to_nl(ex.action) for ex in batch], return_tensors='pt', padding=True, truncation=True,\n",
    "            ).to(self.device)\n",
    "            return_batch['prev_actions_nl'] = self.tokenizer([\n",
    "                '. '.join([\n",
    "                    convert_action_to_nl(action) for action in ex.action_history\n",
    "                ]) for ex in batch], return_tensors='pt', padding=True, truncation=True,\n",
    "            ).to(self.device)\n",
    "        \n",
    "        return return_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a58dca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = TranscriptDataLoader(\n",
    "    train_data, 5, t5_tokenizer, 'cpu', get_nlified_actions=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c65e6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "all_parameters = [p for p in t5_model.parameters() if p.requires_grad]\n",
    "all_parameters = list(set(all_parameters))\n",
    "optimizer = AdamW(all_parameters, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, eval_dl, metrics):\n",
    "    for batch in tqdm(eval_dl):\n",
    "        model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "576e2c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/1525404404.py\u001b[0m(15)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m    decoder_input_ids = torch.cat([\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/1525404404.py\u001b[0m(16)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m    decoder_input_ids = torch.cat([\n",
      "\u001b[0m\u001b[0;32m---> 16 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    ], dim=-1)\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/1525404404.py\u001b[0m(17)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     15 \u001b[0;31m    decoder_input_ids = torch.cat([\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 17 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    ], dim=-1)\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m    decoder_attention_mask = torch.cat([\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/1525404404.py\u001b[0m(15)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m    decoder_input_ids = torch.cat([\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/1525404404.py\u001b[0m(18)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m    ], dim=-1)\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m    decoder_attention_mask = torch.cat([\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> decoder_input_ids.size()\n",
      "*** NameError: name 'decoder_input_ids' is not defined\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/1525404404.py\u001b[0m(15)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m    decoder_input_ids = torch.cat([\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/1525404404.py\u001b[0m(19)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    ], dim=-1)\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m    decoder_attention_mask = torch.cat([\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m        \u001b[0mbatch_prev_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> decoder_input_ids.size()\n",
      "torch.Size([4, 101])\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [165]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     shifted_input_ids\u001b[38;5;241m.\u001b[39mmasked_fill_(shifted_input_ids \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, pad_token_id)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_input_ids, decoder_attention_mask, labels\n\u001b[0;32m---> 36\u001b[0m \u001b[43mmake_batch_inputs_tgts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [165]\u001b[0m, in \u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m(batch_prev_actions, batch_curr_actions, batch_states, decoder_start_token_id, pad_token_id)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m     15\u001b[0m decoder_input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfull((bs,\u001b[38;5;241m1\u001b[39m), decoder_start_token_id),\n\u001b[1;32m     17\u001b[0m     batch_prev_actions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m decoder_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     20\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones((bs,\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mbatch_prev_actions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     21\u001b[0m     batch_prev_actions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     22\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m shifted_input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mnew_zeros(input_ids\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     25\u001b[0m shifted_input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n",
      "Input \u001b[0;32mIn [165]\u001b[0m, in \u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m(batch_prev_actions, batch_curr_actions, batch_states, decoder_start_token_id, pad_token_id)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m     15\u001b[0m decoder_input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfull((bs,\u001b[38;5;241m1\u001b[39m), decoder_start_token_id),\n\u001b[1;32m     17\u001b[0m     batch_prev_actions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m decoder_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     20\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones((bs,\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mbatch_prev_actions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     21\u001b[0m     batch_prev_actions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     22\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m shifted_input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mnew_zeros(input_ids\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     25\u001b[0m shifted_input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/miniconda3/envs/virtualhome/lib/python3.8/bdb.py:88\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;66;03m# None\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_call(frame, arg)\n",
      "File \u001b[0;32m~/miniconda3/envs/virtualhome/lib/python3.8/bdb.py:113\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_here(frame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_here(frame):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_line(frame)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquitting: \u001b[38;5;28;01mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def make_batch_inputs_tgts(\n",
    "    batch_prev_actions,\n",
    "    batch_curr_actions,\n",
    "    batch_states,\n",
    "    decoder_start_token_id: int,\n",
    "    pad_token_id: int,\n",
    "):    \n",
    "    # TODO include environment in `decoder_input_ids` (just the initial state?)\n",
    "    # [bos, batch_prev_actions['input_ids']] -> batch_curr_actions['input_ids'][0]\n",
    "    # [bos, batch_prev_actions['input_ids'], batch_curr_actions['input_ids'][0]] -> batch_curr_actions['input_ids'][1]\n",
    "    # [bos, batch_prev_actions['input_ids'], batch_curr_actions['input_ids'][0:1]]  -> batch_curr_actions['input_ids'][2]\n",
    "    \n",
    "    # 1. concatenate prev_actions and curr_actions\n",
    "    # 2. \n",
    "\n",
    "    bs = batch_prev_actions['input_ids'].size(0)\n",
    "    \n",
    "    decoder_input_ids = torch.cat([\n",
    "        torch.full((bs,1), decoder_start_token_id),\n",
    "        batch_prev_actions['input_ids'],\n",
    "    ], dim=-1)\n",
    "    decoder_attention_mask = torch.cat([\n",
    "        torch.ones((bs,1), dtype=batch_prev_actions['attention_mask'].dtype),\n",
    "        batch_prev_actions['attention_mask'],\n",
    "    ], dim=-1)\n",
    "    import pdb; pdb.set_trace()\n",
    "    \n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[..., 1:] = input_ids[..., :-1].clone()\n",
    "    shifted_input_ids[..., 0] = decoder_start_token_id\n",
    "    \n",
    "    labels = batch_curr_actions\n",
    "    decoder_input_ids = torch.cat([\n",
    "        batch_prev_actions['input_ids'],\n",
    "        t5_model._shift_right(batch_curr_actions['input_ids']),\n",
    "    ])\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "    return decoder_input_ids, decoder_attention_mask, labels\n",
    "\n",
    "make_batch_inputs_tgts(\n",
    "    {'input_ids': torch.rand(4, 100), 'attention_mask': torch.ones(4, 100)},\n",
    "    {'input_ids': torch.rand(4, 10), 'attention_mask': torch.ones(4, 10)},\n",
    "    {}, 0, 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5b9d921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "inf:   0%|                                                                                             | 0/14 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "> \u001b[0;32m/var/folders/c1/xkd4z0yn0fb9gy7nj5w991lh0000gn/T/ipykernel_35736/3169091637.py\u001b[0m(13)\u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m    \u001b[0;31m# [bos, batch['prev_actions']['input_ids'], batch['actions']['input_ids'][0:1]]  -> batch['actions']['input_ids'][2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 13 \u001b[0;31m    \u001b[0mshifted_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0mshifted_input_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m    \u001b[0mshifted_input_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> decoder_start_token_id\n",
      "0\n",
      "ipdb> pad_token_id\n",
      "0\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [159]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_dl, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(lang_loss\u001b[38;5;241m.\u001b[39mitem())):\n\u001b[1;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m     decoder_input_ids, decoder_attention_mask, labels \u001b[38;5;241m=\u001b[39m \u001b[43mmake_batch_inputs_tgts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprev_actions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_start_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt5_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_start_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt5_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m t5_model(\n\u001b[1;32m     17\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoals\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoals\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n",
      "Input \u001b[0;32mIn [158]\u001b[0m, in \u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m(batch_prev_actions, batch_curr_actions, batch_states, decoder_start_token_id, pad_token_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_batch_inputs_tgts\u001b[39m(\n\u001b[1;32m      2\u001b[0m     batch_prev_actions,\n\u001b[1;32m      3\u001b[0m     batch_curr_actions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# [bos, batch['prev_actions']['input_ids'], batch['actions']['input_ids'][0]] -> batch['actions']['input_ids'][1]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# [bos, batch['prev_actions']['input_ids'], batch['actions']['input_ids'][0:1]]  -> batch['actions']['input_ids'][2]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m---> 13\u001b[0m     shifted_input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241m.\u001b[39mnew_zeros(input_ids\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m     shifted_input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     15\u001b[0m     shifted_input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m decoder_start_token_id\n",
      "Input \u001b[0;32mIn [158]\u001b[0m, in \u001b[0;36mmake_batch_inputs_tgts\u001b[0;34m(batch_prev_actions, batch_curr_actions, batch_states, decoder_start_token_id, pad_token_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_batch_inputs_tgts\u001b[39m(\n\u001b[1;32m      2\u001b[0m     batch_prev_actions,\n\u001b[1;32m      3\u001b[0m     batch_curr_actions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# [bos, batch['prev_actions']['input_ids'], batch['actions']['input_ids'][0]] -> batch['actions']['input_ids'][1]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# [bos, batch['prev_actions']['input_ids'], batch['actions']['input_ids'][0:1]]  -> batch['actions']['input_ids'][2]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m---> 13\u001b[0m     shifted_input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241m.\u001b[39mnew_zeros(input_ids\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m     shifted_input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     15\u001b[0m     shifted_input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m decoder_start_token_id\n",
      "File \u001b[0;32m~/miniconda3/envs/virtualhome/lib/python3.8/bdb.py:88\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;66;03m# None\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_call(frame, arg)\n",
      "File \u001b[0;32m~/miniconda3/envs/virtualhome/lib/python3.8/bdb.py:113\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_here(frame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_here(frame):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_line(frame)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquitting: \u001b[38;5;28;01mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "lang_loss = torch.tensor(float(\"inf\"))\n",
    "loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "# train model\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for batch in tqdm.tqdm(train_dl, desc=str(lang_loss.item())):\n",
    "        optimizer.zero_grad()\n",
    "        decoder_input_ids, decoder_attention_mask, labels = make_batch_inputs_tgts(\n",
    "            batch['prev_actions'],\n",
    "            batch['actions'],\n",
    "            batch['states'],\n",
    "            decoder_start_token_id = t5_model.config.decoder_start_token_id,\n",
    "            pad_token_id = t5_model.config.pad_token_id\n",
    "        )\n",
    "        import pdb; pdb.set_trace()\n",
    "        return_dict = t5_model(\n",
    "            input_ids=batch['goals']['input_ids'],\n",
    "            attention_mask=batch['goals']['attention_mask'],\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        loss = loss_fct(\n",
    "            return_dict.logits.view(-1, return_dict.logits.size(-1)),\n",
    "            batch['actions']['input_ids'].view(-1),\n",
    "        )\n",
    "        try:\n",
    "            return_dict = t5_model(\n",
    "                input_ids=batch['goals']['input_ids'],\n",
    "                attention_mask=batch['goals']['attention_mask'],\n",
    "                decoder_input_ids=batch['prev_actions']['input_ids'],\n",
    "                decoder_attention_mask=batch['prev_actions']['attention_mask'],\n",
    "                labels=batch['actions']['input_ids'],\n",
    "                return_dict=True,\n",
    "            )\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "            return_dict = t5_model(input_ids=batch['goals']['input_ids'], attention_mask=batch['goals']['attention_mask'], decoder_input_ids=batch['prev_actions']['input_ids'], decoder_attention_mask=batch['prev_actions']['attention_mask'], labels=batch['actions']['input_ids'], return_dict=True,)\n",
    "        lang_loss, dec_output, encoder_hidden = return_dict.loss, return_dict.logits, return_dict.encoder_last_hidden_state\n",
    "        lang_loss = lang_loss.mean()\n",
    "        lang_loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba293ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
